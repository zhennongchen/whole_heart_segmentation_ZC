{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training, Validation and testing dataset were labeled by batch manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/host/d/Github')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nb\n",
    "import whole_heart_segmentation_ZC.functions_collection as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/host/d/Data/WHS/current_challenge/original_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select batches for training, validation\n",
    "#### here, we need to split both CT and MR into 5 bachces respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(n_samples, n_batches=5,shuffle = None, seed=None):\n",
    "    \"\"\"\n",
    "    先 shuffle，然后把 index 分成 n_batches 个 batch。\n",
    "    \"\"\"\n",
    "\n",
    "    assert shuffle in [True, False], \"shuffle must be True or False\"\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # step 1: shuffle\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(n_samples)   # 生成 0~n_samples-1 并打乱顺序\n",
    "    else:\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "    # step 2: average split\n",
    "    batch_list = np.zeros(n_samples, dtype=int)\n",
    "    batch_size = n_samples // n_batches\n",
    "    remainder = n_samples % n_batches\n",
    "\n",
    "    start = 0\n",
    "    for i in range(n_batches):\n",
    "        size = batch_size + (1 if i == n_batches - 1 and remainder > 0 else 0)\n",
    "        batch_list[indices[start:start+size]] = i\n",
    "        start += size\n",
    "    \n",
    "    return batch_list.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_list = ['CT','MR']\n",
    "random_seed = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of CT cases: 40\n",
      "Total number of MR cases: 46\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "basic_info = pd.read_excel('/host/d/Data/WHS/Patient_lists/original_data_info.xlsx', dtype = {'patient_id': str})\n",
    "for modality_num in range(len(modality_list)):\n",
    "    modality_name = modality_list[modality_num]\n",
    "   \n",
    "    cases = ff.find_all_target_files(['center*/*'],os.path.join(main_path,modality_name))\n",
    "    num_of_cases = len(cases)\n",
    "    print('Total number of {} cases: {}'.format(modality_name, num_of_cases))\n",
    "    batch_list = make_batches(num_of_cases, n_batches=5, shuffle=True, seed=random_seed)\n",
    "\n",
    "    for n in range(0,num_of_cases):\n",
    "\n",
    "        batch = batch_list[n]\n",
    "        case_path = cases[n]\n",
    "\n",
    "        case_id = os.path.basename(case_path)\n",
    "        center = os.path.basename(os.path.dirname(case_path))\n",
    "\n",
    "        row = basic_info[(basic_info['modality']==modality_name) & \n",
    "                         (basic_info['center']==center) & \n",
    "                         (basic_info['patient_id']==case_id)]\n",
    "\n",
    "        \n",
    "        results.append([batch, modality_name, center, case_id,\n",
    "                        int(row['size_x']), int(row['size_y']), int(row['size_z']),\n",
    "                        float(row['spacing_x']), float(row['spacing_y']), float(row['spacing_z'])])\n",
    "            \n",
    "df = pd.DataFrame(results, columns=['batch','modality','center','patient_id',\n",
    "                                    'size_x','size_y','size_z',\n",
    "                                    'spacing_x','spacing_y','spacing_z'])\n",
    "ff.make_folder([os.path.join('/host/d/Data/WHS/Patient_lists')])\n",
    "df.to_excel(os.path.join('/host/d/Data/WHS/Patient_lists','train_val_batch_list.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make patient list for train and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = pd.read_excel(os.path.join('/host/d/Data/WHS/Patient_lists','train_val_batch_list.xlsx'), dtype = {'patient_id': str})\n",
    "main_path = '/host/d/Data/WHS/current_challenge/original_data'\n",
    "\n",
    "img_list = []\n",
    "label_list = []\n",
    "for i in range(len(batch_list)):\n",
    "    modality = batch_list.loc[i,'modality']\n",
    "    center = batch_list.loc[i,'center']\n",
    "    patient_id = batch_list.loc[i,'patient_id']\n",
    "    \n",
    "    img_path = os.path.join(main_path, modality, center, patient_id, 'image.nii.gz')\n",
    "    label_path = os.path.join(main_path, modality, center, patient_id, 'label.nii.gz')\n",
    "    \n",
    "    img_list.append(img_path)\n",
    "    label_list.append(label_path)\n",
    "\n",
    "batch_list['img_path'] = img_list\n",
    "batch_list['label_path'] = label_list\n",
    "batch_list.to_excel(os.path.join('/host/d/Data/WHS/Patient_lists','train_val_path_list.xlsx'), index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
